{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inpainting.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNpQfb3vNS/bWpusroMvTzp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ShXE8UZ5NNxW"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","class DMFB(nn.Module):\n","  def __init__(self,cin):\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(cin, cin, 1)\n","    self.conv2 = nn.Conv2d(cin, cin, 1)\n","    self.conv3 = nn.Conv2d(cin, cin, 1)\n","    self.conv4 = nn.Conv2d(cin, cin, 1)\n","    self.k2 = nn.Conv2d(cin, cin, 3, padding=1)\n","    self.k3 = nn.Conv2d(cin, cin, 5, padding=2)\n","    self.k4 = nn.Conv2d(cin, cin, 7, padding=3)\n","  \n","  def forward(self,x):\n","    x1 = self.conv1(x)\n","    x2 = self.conv2(x)\n","    x3 = self.conv3(x)\n","    x4 = self.conv4(x)\n","    x5 = self.k2(x1+x2)\n","    x6 = self.k3(x5+x3)\n","    x7 = self.k4(x6+x4)\n","    \n","    return x1+x5+x6+x7\n","\n","\n","class PartialConvLayer (nn.Module):\n","\n","  def __init__(self, in_channels, out_channels,stride = 2, bn=True, bias=False, activation=\"relu\"):\n","    super().__init__()\n","    self.bn = bn\n","\n","    self.input_conv = nn.Conv2d(in_channels, out_channels, 3, stride ,1, bias=bias)\n","    self.mask_conv = nn.Conv2d(in_channels, out_channels, 3, stride ,1, bias=False)\n","\n","    nn.init.constant_(self.mask_conv.weight, 1.0)\n","\n","    # \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\"\n","    # negative slope of leaky_relu set to 0, same as relu\n","    # \"fan_in\" preserved variance from forward pass\n","    nn.init.kaiming_normal_(self.input_conv.weight, a=0, mode=\"fan_in\")\n","\n","    for param in self.mask_conv.parameters():\n","      param.requires_grad = False\n","\n","    if bn:\n","      # Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n","      # Applying BatchNorm2d layer after Conv will remove the channel mean\n","      self.batch_normalization = nn.BatchNorm2d(out_channels)\n","\n","    if activation == \"relu\":\n","      # Used between all encoding layers\n","      self.activation = nn.ReLU()\n","    elif activation == \"leaky_relu\":\n","      # Used between all decoding layers (Leaky RELU with alpha = 0.2)\n","      self.activation = nn.LeakyReLU(negative_slope=0.2)\n","\n","  def forward(self, input_x, mask):\n","    # output = W^T dot (X .* M) + b\n","    output = self.input_conv(input_x )#* mask)\n","\n","    # requires_grad = False\n","    with torch.no_grad():\n","      # mask = (1 dot M) + 0 = M\n","      output_mask = self.mask_conv(mask)\n","\n","    if self.input_conv.bias is not None:\n","      # spreads existing bias values out along 2nd dimension (channels) and then expands to output size\n","      output_bias = self.input_conv.bias.view(1, -1, 1, 1).expand_as(output)\n","    else:\n","      output_bias = torch.zeros_like(output)\n","\n","    # mask_sum is the sum of the binary mask at every partial convolution location\n","    mask_is_zero = (output_mask == 0)\n","    # temporarily sets zero values to one to ease output calculation \n","    mask_sum = output_mask.masked_fill_(mask_is_zero, 1.0)\n","\n","    # output at each location as follows:\n","    # output = (W^T dot (X .* M) + b - b) / M_sum + b ; if M_sum > 0\n","    # output = 0 ; if M_sum == 0\n","    output = (output - output_bias) / mask_sum + output_bias\n","    output = output.masked_fill_(mask_is_zero, 0.0)\n","\n","    # mask is updated at each location\n","    new_mask = torch.ones_like(output)\n","    new_mask = new_mask.masked_fill_(mask_is_zero, 0.0)\n","\n","    if self.bn:\n","      output = self.batch_normalization(output)\n","\n","    if hasattr(self, 'activation'):\n","      output = self.activation(output)\n","\n","    return output, new_mask\n","\n","\n","class PartialConvUNet(nn.Module):\n","\n","  # 256 x 256 image input, 256 = 2^8\n","  def __init__(self, input_size=256, layers=5):\n","    #if 2 ** (layers + 1) != input_size:\n","    #  raise AssertionError\n","\n","    super().__init__()\n","    self.freeze_enc_bn = False\n","    self.layers = layers\n","\n","    # ======================= ENCODING LAYERS =======================\n","    # 3x256x256 --> 64x128x128\n","    self.encoder_1 = PartialConvLayer(3, 64, bn=False)\n","\n","    # 64x128x128 --> 128x64x64\n","    self.encoder_2 = PartialConvLayer(64, 128)\n","    self.dmfb_1 = DMFB(128)\n","\n","    # 128x64x64 --> 256x32x32\n","    self.encoder_3 = PartialConvLayer(128, 256)\n","    self.dmfb_2 = DMFB(256)\n","\n","    # 256x32x32 --> 512x16x16\n","    self.encoder_4 = PartialConvLayer(256, 512)\n","\n","    # 512x16x16 --> 512x8x8 --> 512x4x4 --> 512x2x2\n","    #for i in range(5, layers + 1):\n","    #  name = \"encoder_{:d}\".format(i)\n","    #  setattr(self, name, PartialConvLayer(512, 512))\n","\n","    # ======================= DECODING LAYERS =======================\n","    # dec_7: UP(512x2x2) + 512x4x4(enc_6 output) = 1024x4x4 --> 512x4x4\n","    # dec_6: UP(512x4x4) + 512x8x8(enc_5 output) = 1024x8x8 --> 512x8x8\n","    # dec_5: UP(512x8x8) + 512x16x16(enc_4 output) = 1024x16x16 --> 512x16x16\n","    #for i in range(5, layers + 1):\n","    #  name = \"decoder_{:d}\".format(i)\n","    #  setattr(self, name, PartialConvLayer(512, 512, activation=\"leaky_relu\"))\n","\n","    # UP(512x16x16) + 256x32x32(enc_3 output) = 768x32x32 --> 256x32x32\n","    self.decoder_4 = PartialConvLayer(512 , 256, stride = 1 , activation=\"leaky_relu\")\n","\n","    # UP(256x32x32) + 128x64x64(enc_2 output) = 384x64x64 --> 128x64x64\n","    self.decoder_3 = PartialConvLayer(256 , 128, stride = 1 , activation=\"leaky_relu\")\n","\n","    # UP(128x64x64) + 64x128x128(enc_1 output) = 192x128x128 --> 64x128x128\n","    self.decoder_2 = PartialConvLayer(128 , 64, stride = 1,  activation=\"leaky_relu\")\n","\n","    # UP(64x128x128) + 3x256x256(original image) = 67x256x256 --> 3x256x256(final output)\n","    self.decoder_1 = PartialConvLayer(64 , 3, stride = 1 , bn=False, activation=\"\", bias=True)\n","\t\n","  def forward(self, input_x, mask):\n","    encoder_dict = {}\n","    mask_dict = {}\n","\n","    key_prev = \"h_0\"\n","    encoder_dict[key_prev], mask_dict[key_prev] = input_x, mask\n","\n","    for i in range(1, self.layers):\n","      encoder_key = \"encoder_{:d}\".format(i)\n","      key = \"h_{:d}\".format(i)\n","      # Passes input and mask through encoding layer\n","      encoder_dict[key], mask_dict[key] = getattr(self, encoder_key)(encoder_dict[key_prev], mask_dict[key_prev])\n","      if encoder_key == \"encoder_2\":\n","        encoder_dict[key]= self.dmfb_1(encoder_dict[key])\n","      if encoder_key == \"encoder_3\":\n","        encoder_dict[key]= self.dmfb_2(encoder_dict[key])\n","      key_prev = key\n","      #print()\n","      #print(encoder_dict[key].shape)\n","\n","    # Gets the final output data and mask from the encoding layers\n","    # 512 x 2 x 2\n","    out_key = \"h_{:d}\".format(self.layers-1)\n","    out_data, out_mask = encoder_dict[out_key], mask_dict[out_key]\n","    #print(out_data.shape)\n","    #print(\"encoder over\")\n","\n","    for i in range(self.layers-1, 0, -1):\n","      encoder_key = \"h_{:d}\".format(i)\n","      decoder_key = \"decoder_{:d}\".format(i)\n","\n","      # Upsample to 2 times scale, matching dimensions of previous encoding layer output\n","      out_data = F.interpolate(out_data, scale_factor=2)\n","      out_mask = F.interpolate(out_mask, scale_factor=2)\n","\n","      # concatenate upsampled decoder output with encoder output of same H x W dimensions\n","      # s.t. final decoding layer input will contain the original image\n","      #out_data = torch.cat([out_data, encoder_dict[encoder_key]], dim=1)\n","      # also concatenate the masks\n","      #out_mask = torch.cat([out_mask, mask_dict[encoder_key]], dim=1)\n","\t\t\t\n","      # feed through decoder layers\n","      out_data, out_mask = getattr(self, decoder_key)(out_data, out_mask)\n","      #print(out_data.shape)\n","\n","    return out_data\n","\n","  def train(self, mode=True):\n","    super().train(mode)\n","    if self.freeze_enc_bn:\n","      for name, module in self.named_modules():\n","        if isinstance(module, nn.BatchNorm2d) and \"enc\" in name:\n","          # Sets batch normalization layers to evaluation mode\n","          module.eval()\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, channels=3):\n","        super(Discriminator, self).__init__()\n","\n","        def discriminator_block(in_filters, out_filters, stride, normalize):\n","            \"\"\"Returns layers of each discriminator block\"\"\"\n","            layers = [nn.Conv2d(in_filters, out_filters, 3, stride, 1)]\n","            if normalize:\n","                layers.append(nn.InstanceNorm2d(out_filters))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return layers\n","\n","        layers = []\n","        in_filters = channels\n","        for out_filters, stride, normalize in [(64, 2, False), (128, 2, True), (256, 2, True), (512, 1, True)]:\n","            layers.extend(discriminator_block(in_filters, out_filters, stride, normalize))\n","            in_filters = out_filters\n","\n","        layers.append(nn.Conv2d(out_filters, 1, 3, 1, 1))\n","\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, img):\n","        return self.model(img)\n","\n","def get_pixel(img, center, x, y):\n","\n","    new_value = 0\n","    try:\n","        if img[x][y] >= center:\n","            new_value = 1\n","\n","    except:\n","        pass\n","    return new_value\n","\n","def lbp(img, x, y):\n","\n","    center = img[x][y]\n","    val_ar = []\n","    val_ar.append(get_pixel(img, center, x-1, y-1))\n","    val_ar.append(get_pixel(img, center, x-1, y))\n","    val_ar.append(get_pixel(img, center, x-1, y + 1))\n","    val_ar.append(get_pixel(img, center, x, y + 1))\n","    val_ar.append(get_pixel(img, center, x + 1, y + 1))\n","    val_ar.append(get_pixel(img, center, x + 1, y))\n","    val_ar.append(get_pixel(img, center, x + 1, y-1))\n","    val_ar.append(get_pixel(img, center, x, y-1))\n","\n","    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n","\n","    val = 0\n","    for i in range(len(val_ar)):\n","        val += val_ar[i] * power_val[i]\n","    return val\n","\n","if __name__ == '__main__':\n","  inp = \n","  inp1 = inp.reshape(256,256,3)\n","  plt.subplot(1,2,1)\n","  plt.imshow(inp1)\n","  input_mask = torch.ones(size)\n","  #input_mask[:, :, :, :][:, :, :, :] = 1\n","\n","  conv = PartialConvUNet()\n","  #print(conv)\n","  #conv.to(torch.device(\"cuda:0\"))\n","  output = conv(inp, input_mask) \n","  #plt.imshow(output.detach().numpy()[0])\n","  output = output[0]\n","  x,y,z = output.shape\n","  output = output.reshape(256,256,3)\n","  plt.subplot(1,2,2)\n","  plt.imshow(output.detach().numpy())\n","  print(output.shape)\n"],"execution_count":null,"outputs":[]}]}